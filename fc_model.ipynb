{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fc_model",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wL9eLV933X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
        "      self.hidden_layers=nn.ModeuleList([nn.Linear(input_size,hidden_layers[0])])\n",
        "      layer_sizes=zip(hidden_layers[:-1],hidden_layers[1:])\n",
        "      self.hidden_layers.extend([nn.Linear(h1,h2) for h1,h2 in layer_sizes])\n",
        "      self.output=nn.Linear(hidden_layers[-1],output_size)\n",
        "      self.dropout=nn.Dropout(p=drop_p)\n",
        "      def forward(self,x):\n",
        "        for each in self.hidden_layers:\n",
        "          x=F.relu(each(x))\n",
        "          x=self.dropout(x)\n",
        "        x=self.output(x)\n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec_C5GqD-AlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}