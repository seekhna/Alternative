{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to PyTorch-Training Neural Networks",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmljSdc50BzT",
        "colab_type": "code",
        "outputId": "86c27e95-bc6b-48d2-f499-62ffb7dba105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9299077.56it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 137192.28it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2242103.61it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51850.69it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw7nap_Lbu7w",
        "colab_type": "code",
        "outputId": "3c472faa-a014-4ac7-dff9-cbcd51705d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-18 18:05:08--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4tQhY87MCDD",
        "colab_type": "code",
        "outputId": "75ee2ab1-76c2-46ca-a691-46c348278257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "print(images.shape)\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "print(images.shape)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 784])\n",
            "tensor(2.3286, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAS4uDwgMNv4",
        "colab_type": "code",
        "outputId": "fa6aee75-f7ae-4120-be1e-41f41d7e311e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1)\n",
        "                      )\n",
        "\n",
        "# Define the loss\n",
        "loss = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "print(images.shape)\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "print(images.shape)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logps= model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = loss(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 784])\n",
            "tensor(2.3092, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCxZk-PlO7Rn",
        "colab_type": "code",
        "outputId": "03f86de1-92c7-4bb4-cdac-92027e7d651c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 0.0024,  0.0024,  0.0024,  ...,  0.0024,  0.0024,  0.0024],\n",
            "        [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
            "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
            "        ...,\n",
            "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
            "        [ 0.0031,  0.0031,  0.0031,  ...,  0.0031,  0.0031,  0.0031],\n",
            "        [-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKKu8huSSOcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlbdUFRuSi2O",
        "colab_type": "code",
        "outputId": "a234f37f-2a41-4852-cef7-0f6b625bffd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0016, -0.0334, -0.0206,  ..., -0.0126,  0.0036, -0.0204],\n",
            "        [-0.0248, -0.0169, -0.0002,  ..., -0.0320, -0.0100, -0.0289],\n",
            "        [ 0.0302,  0.0175, -0.0268,  ...,  0.0333,  0.0292, -0.0053],\n",
            "        ...,\n",
            "        [-0.0086,  0.0175,  0.0293,  ...,  0.0124, -0.0315,  0.0172],\n",
            "        [-0.0350,  0.0356,  0.0121,  ..., -0.0276, -0.0099, -0.0250],\n",
            "        [ 0.0058, -0.0225, -0.0242,  ..., -0.0080, -0.0072, -0.0323]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0017,  0.0017,  0.0017,  ...,  0.0017,  0.0017,  0.0017],\n",
            "        [-0.0039, -0.0039, -0.0039,  ..., -0.0039, -0.0039, -0.0039],\n",
            "        [ 0.0024,  0.0024,  0.0024,  ...,  0.0024,  0.0024,  0.0024],\n",
            "        ...,\n",
            "        [ 0.0059,  0.0059,  0.0059,  ...,  0.0059,  0.0059,  0.0059],\n",
            "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
            "        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV3a8Q1TUg1a",
        "colab_type": "code",
        "outputId": "5a731819-64bc-4b37-9e1c-1a17c6bdd2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0015, -0.0334, -0.0206,  ..., -0.0126,  0.0036, -0.0205],\n",
            "        [-0.0248, -0.0169, -0.0002,  ..., -0.0320, -0.0099, -0.0289],\n",
            "        [ 0.0302,  0.0175, -0.0268,  ...,  0.0333,  0.0292, -0.0054],\n",
            "        ...,\n",
            "        [-0.0087,  0.0174,  0.0292,  ...,  0.0124, -0.0316,  0.0171],\n",
            "        [-0.0350,  0.0356,  0.0121,  ..., -0.0276, -0.0099, -0.0250],\n",
            "        [ 0.0058, -0.0225, -0.0242,  ..., -0.0080, -0.0072, -0.0323]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrMKCBP4U2Ip",
        "colab_type": "code",
        "outputId": "13991be7-efa3-4287-981e-102ef280bbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.9894606656611347\n",
            "Training loss: 0.9199215104140198\n",
            "Training loss: 0.5585655207509426\n",
            "Training loss: 0.4468488983635201\n",
            "Training loss: 0.39465291642431005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnY2Y2epbJ4i",
        "colab_type": "code",
        "outputId": "7f6503b0-bc64-4e57-eb24-6aa8cfe885d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSBIFCgCQJAoUACBJFCgAQJL+H/Is5ZGCK2Y8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FJFSvNdbpkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}